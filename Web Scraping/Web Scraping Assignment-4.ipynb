{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b411ba89",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment-4****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d00f5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import necessary libraries:\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementClickInterceptedException, NoSuchElementException, StaleElementReferenceException, ElementNotInteractableException\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8907f",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8beb9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')\n",
    "driver.maximize_window()\n",
    "url=(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e395dcb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 49 49 49 49\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>\"Baby Shark Dance\"[4]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>7,046,700,000</td>\n",
       "      <td>November 2, 2020</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\"Despacito\"[7]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>2,993,700,000</td>\n",
       "      <td>August 4, 2017</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\"See You Again\"[18]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>2,894,000,000</td>\n",
       "      <td>July 10, 2017</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>\"Gangnam Style\"⁂[27]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>803,700,000</td>\n",
       "      <td>November 24, 2012</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>\"Baby\"*[63]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>245,400,000</td>\n",
       "      <td>July 16, 2010</td>\n",
       "      <td>February 19, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\"Bad Romance\"[67]</td>\n",
       "      <td>Lady Gaga</td>\n",
       "      <td>178,400,000</td>\n",
       "      <td>April 14, 2010</td>\n",
       "      <td>November 24, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\"Charlie Bit My Finger\"‡[71]</td>\n",
       "      <td>HDCYT</td>\n",
       "      <td>128,900,000</td>\n",
       "      <td>October 25, 2009</td>\n",
       "      <td>May 22, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>\"Evolution of Dance\"[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>118,900,000</td>\n",
       "      <td>May 2, 2009</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>\"Girlfriend\"‡[76][77]</td>\n",
       "      <td>RCA Records</td>\n",
       "      <td>92,600,000</td>\n",
       "      <td>July 17, 2008</td>\n",
       "      <td>February 27, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>\"Evolution of Dance\"[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>78,400,000</td>\n",
       "      <td>March 15, 2008</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>\"Music Is My Hot Hot Sex\"‡[81]</td>\n",
       "      <td>CLARUSBARTEL72</td>\n",
       "      <td>76,600,000</td>\n",
       "      <td>March 1, 2008</td>\n",
       "      <td>April 9, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>\"Evolution of Dance\"*[74]</td>\n",
       "      <td>Judson Laipply</td>\n",
       "      <td>10,600,000</td>\n",
       "      <td>May 19, 2006</td>\n",
       "      <td>April 6, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>\"Pokémon Theme Music Video\"‡[87]</td>\n",
       "      <td>Smosh</td>\n",
       "      <td>4,300,000</td>\n",
       "      <td>March 12, 2006</td>\n",
       "      <td>November 28, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>\"Myspace – The Movie\"‡[92][93]</td>\n",
       "      <td>eggtea</td>\n",
       "      <td>2,700,000</td>\n",
       "      <td>February 18, 2006</td>\n",
       "      <td>January 31, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>\"Phony Photo Booth\"‡[96]</td>\n",
       "      <td>mugenized</td>\n",
       "      <td>3,400,000</td>\n",
       "      <td>January 21, 2006</td>\n",
       "      <td>December 1, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\"The Chronic of Narnia Rap\"‡[98]</td>\n",
       "      <td>youtubedude</td>\n",
       "      <td>2,300,000</td>\n",
       "      <td>January 9, 2006</td>\n",
       "      <td>December 18, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>\"Ronaldinho: Touch of Gold\"‡*[100]</td>\n",
       "      <td>Nikesoccer</td>\n",
       "      <td>255,000</td>\n",
       "      <td>October 31, 2005</td>\n",
       "      <td>October 21, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>\"I/O Brush\"‡*[103]</td>\n",
       "      <td>larfus</td>\n",
       "      <td>247,000</td>\n",
       "      <td>October 29, 2005</td>\n",
       "      <td>October 5, 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>\"Me at the zoo\"[105]</td>\n",
       "      <td>jawed</td>\n",
       "      <td>1</td>\n",
       "      <td>April 23, 2005</td>\n",
       "      <td>April 23, 2005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Rank  \\\n",
       "0                                   1.   \n",
       "1                                   2.   \n",
       "2                                   3.   \n",
       "3                                   4.   \n",
       "4                                   5.   \n",
       "5                                   6.   \n",
       "6                                   7.   \n",
       "7                                   8.   \n",
       "8                                   9.   \n",
       "9                                  10.   \n",
       "10                                 11.   \n",
       "11                                 12.   \n",
       "12                                 13.   \n",
       "13                                 14.   \n",
       "14                                 15.   \n",
       "15                                 16.   \n",
       "16                                 17.   \n",
       "17                                 18.   \n",
       "18                                 19.   \n",
       "19                                 20.   \n",
       "20                                 21.   \n",
       "21                                 22.   \n",
       "22                                 23.   \n",
       "23                                 24.   \n",
       "24                                 25.   \n",
       "25                                 26.   \n",
       "26                                 27.   \n",
       "27                                 28.   \n",
       "28                                 29.   \n",
       "29                                 30.   \n",
       "30               \"Baby Shark Dance\"[4]   \n",
       "31                      \"Despacito\"[7]   \n",
       "32                 \"See You Again\"[18]   \n",
       "33                \"Gangnam Style\"⁂[27]   \n",
       "34                         \"Baby\"*[63]   \n",
       "35                   \"Bad Romance\"[67]   \n",
       "36        \"Charlie Bit My Finger\"‡[71]   \n",
       "37            \"Evolution of Dance\"[74]   \n",
       "38               \"Girlfriend\"‡[76][77]   \n",
       "39            \"Evolution of Dance\"[74]   \n",
       "40      \"Music Is My Hot Hot Sex\"‡[81]   \n",
       "41           \"Evolution of Dance\"*[74]   \n",
       "42    \"Pokémon Theme Music Video\"‡[87]   \n",
       "43      \"Myspace – The Movie\"‡[92][93]   \n",
       "44            \"Phony Photo Booth\"‡[96]   \n",
       "45    \"The Chronic of Narnia Rap\"‡[98]   \n",
       "46  \"Ronaldinho: Touch of Gold\"‡*[100]   \n",
       "47                  \"I/O Brush\"‡*[103]   \n",
       "48                \"Me at the zoo\"[105]   \n",
       "\n",
       "                                           Name  \\\n",
       "0                            \"Baby Shark Dance\"   \n",
       "1                                   \"Despacito\"   \n",
       "2                        \"Johny Johny Yes Papa\"   \n",
       "3                                   \"Bath Song\"   \n",
       "4                                \"Shape of You\"   \n",
       "5                               \"See You Again\"   \n",
       "6                 \"Phonics Song with Two Words\"   \n",
       "7                           \"Wheels on the Bus\"   \n",
       "8                                 \"Uptown Funk\"   \n",
       "9   \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "10                              \"Gangnam Style\"   \n",
       "11   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "12                             \"Dame Tu Cosita\"   \n",
       "13                                      \"Sugar\"   \n",
       "14                                     \"Axel F\"   \n",
       "15                                       \"Roar\"   \n",
       "16                             \"Counting Stars\"   \n",
       "17                                      \"Sorry\"   \n",
       "18                          \"Thinking Out Loud\"   \n",
       "19                        \"Baa Baa Black Sheep\"   \n",
       "20           \"Waka Waka (This Time for Africa)\"   \n",
       "21                                 \"Dark Horse\"   \n",
       "22                                      \"Faded\"   \n",
       "23                                 \"Let Her Go\"   \n",
       "24                             \"Girls Like You\"   \n",
       "25                                    \"Perfect\"   \n",
       "26                                   \"Bailando\"   \n",
       "27                                    \"Lean On\"   \n",
       "28          \"Humpty the train on a fruits ride\"   \n",
       "29                             \"Lakdi Ki Kathi\"   \n",
       "30  Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "31                                   Luis Fonsi   \n",
       "32                                  Wiz Khalifa   \n",
       "33                                          Psy   \n",
       "34                                Justin Bieber   \n",
       "35                                    Lady Gaga   \n",
       "36                                        HDCYT   \n",
       "37                               Judson Laipply   \n",
       "38                                  RCA Records   \n",
       "39                               Judson Laipply   \n",
       "40                               CLARUSBARTEL72   \n",
       "41                               Judson Laipply   \n",
       "42                                        Smosh   \n",
       "43                                       eggtea   \n",
       "44                                    mugenized   \n",
       "45                                  youtubedude   \n",
       "46                                   Nikesoccer   \n",
       "47                                       larfus   \n",
       "48                                        jawed   \n",
       "\n",
       "                                           Artist        Upload_date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                       Maroon 5   January 14, 2015   \n",
       "14                                     Crazy Frog      June 16, 2009   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                                     Ed Sheeran    October 7, 2014   \n",
       "19                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                      Passenger      July 25, 2012   \n",
       "24                                       Maroon 5       May 31, 2018   \n",
       "25                                     Ed Sheeran   November 9, 2017   \n",
       "26                               Enrique Iglesias     April 11, 2014   \n",
       "27                                    Major Lazer     March 22, 2015   \n",
       "28  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "29                                   Jingle Toons      June 14, 2018   \n",
       "30                                  7,046,700,000   November 2, 2020   \n",
       "31                                  2,993,700,000     August 4, 2017   \n",
       "32                                  2,894,000,000      July 10, 2017   \n",
       "33                                    803,700,000  November 24, 2012   \n",
       "34                                    245,400,000      July 16, 2010   \n",
       "35                                    178,400,000     April 14, 2010   \n",
       "36                                    128,900,000   October 25, 2009   \n",
       "37                                    118,900,000        May 2, 2009   \n",
       "38                                     92,600,000      July 17, 2008   \n",
       "39                                     78,400,000     March 15, 2008   \n",
       "40                                     76,600,000      March 1, 2008   \n",
       "41                                     10,600,000       May 19, 2006   \n",
       "42                                      4,300,000     March 12, 2006   \n",
       "43                                      2,700,000  February 18, 2006   \n",
       "44                                      3,400,000   January 21, 2006   \n",
       "45                                      2,300,000    January 9, 2006   \n",
       "46                                        255,000   October 31, 2005   \n",
       "47                                        247,000   October 29, 2005   \n",
       "48                                              1     April 23, 2005   \n",
       "\n",
       "                Views  \n",
       "0               12.27  \n",
       "1                8.08  \n",
       "2                6.61  \n",
       "3                6.01  \n",
       "4                5.91  \n",
       "5                5.78  \n",
       "6                5.15  \n",
       "7                4.92  \n",
       "8                4.83  \n",
       "9                4.81  \n",
       "10               4.69  \n",
       "11               4.53  \n",
       "12               4.23  \n",
       "13               3.82  \n",
       "14               3.75  \n",
       "15               3.73  \n",
       "16               3.72  \n",
       "17               3.63  \n",
       "18               3.55  \n",
       "19               3.49  \n",
       "20               3.47  \n",
       "21               3.45  \n",
       "22               3.40  \n",
       "23               3.38  \n",
       "24               3.37  \n",
       "25               3.37  \n",
       "26               3.33  \n",
       "27               3.33  \n",
       "28               3.30  \n",
       "29               3.30  \n",
       "30      June 17, 2016  \n",
       "31   January 12, 2017  \n",
       "32      April 6, 2015  \n",
       "33      July 15, 2012  \n",
       "34  February 19, 2010  \n",
       "35  November 24, 2009  \n",
       "36       May 22, 2007  \n",
       "37      April 6, 2006  \n",
       "38  February 27, 2007  \n",
       "39      April 6, 2006  \n",
       "40      April 9, 2007  \n",
       "41      April 6, 2006  \n",
       "42  November 28, 2005  \n",
       "43   January 31, 2006  \n",
       "44   December 1, 2005  \n",
       "45  December 18, 2005  \n",
       "46   October 21, 2005  \n",
       "47    October 5, 2005  \n",
       "48     April 23, 2005  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank= []\n",
    "Name= []\n",
    "Artist= []\n",
    "Upload_date= []\n",
    "Views= []\n",
    "\n",
    "#scraping Rank\n",
    "try:\n",
    "    Rank_tag= driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[1]\")\n",
    "    for i in Rank_tag:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Rank.append(\"--\")\n",
    "\n",
    "#scraping Name\n",
    "try:\n",
    "    Name_tag= driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[2]\")\n",
    "    for i in Name_tag:\n",
    "        Name.append(i.text.split('[')[0])\n",
    "except NoSuchElementException as e:\n",
    "    Name.append(\"--\") \n",
    "\n",
    "#scraping Artist\n",
    "try:\n",
    "    Artist_tag= driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[3]\")\n",
    "    for i in Artist_tag:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Artist.append(\"--\")\n",
    "\n",
    "#scraping Upload date\n",
    "try:\n",
    "    Upload_tag= driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[5]\")\n",
    "    for i in Upload_tag:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Upload_date.append(\"--\")\n",
    "\n",
    "#Scraping views\n",
    "try:\n",
    "    View_tag= driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter']/tbody/tr/td[4]\")\n",
    "    for i in View_tag:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Views.append(\"--\")\n",
    "    \n",
    "#printing length\n",
    "print(len(Rank),len(Name),len(Artist),len(Upload_date),len(Views))\n",
    "\n",
    "#creating DataFrame\n",
    "viewed_videos=pd.DataFrame({\"Rank\":Rank,\"Name\":Name,\"Artist\":Artist,\"Upload_date\":Upload_date,\"Views\":Views})\n",
    "viewed_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d454880e",
   "metadata": {},
   "source": [
    "# 2. Scrape the details team India’s internationalfixtures from bcci.tv. \n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "\n",
    "     Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207fac3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_2=webdriver.Chrome('chromedriver.exe')\n",
    "driver_2.maximize_window()\n",
    "url=(\"https://www.bcci.tv/\")\n",
    "driver_2.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d4ef1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on menu\n",
    "button= driver_2.find_element(By.XPATH,'//span[@class = \"menu-icon__line menu-icon__line-right\"]').get_attribute('href')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9c89a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting International\n",
    "International= driver_2.find_element(By.XPATH,'//a[@class = \"nav-link \"]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b0cf5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on dropdown\n",
    "Select= driver_2.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[1]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f9b4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting ODI\n",
    "OdI= driver_2.find_element(By.XPATH,'/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[3]/div/div[2]/div[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edd9e3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3 3 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Wankhede Stadium, Mumbai,Match Centre</td>\n",
       "      <td>17 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>19 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai,Match Centre</td>\n",
       "      <td>22 MAR 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Match_title    Series  \\\n",
       "0  AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23  1st ODI    \n",
       "1  AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23  2nd ODI    \n",
       "2  AUSTRALIA TOUR OF INDIA ODI SERIES 2022-23  3rd ODI    \n",
       "\n",
       "                                           Place         Date         Time  \n",
       "0          Wankhede Stadium, Mumbai,Match Centre  17 MAR 2023  1:30 PM IST  \n",
       "1                    Dr YS Rajasekhara Reddy ACA  19 MAR 2023  1:30 PM IST  \n",
       "2   MA Chidambaram Stadium, Chennai,Match Centre  22 MAR 2023  1:30 PM IST  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Match_title= []\n",
    "Series= []\n",
    "Place= []\n",
    "Date= []\n",
    "Time= []\n",
    "\n",
    "#scraping Match Title\n",
    "try:\n",
    "    Match_title_tag= driver_2.find_elements(By.XPATH,\"//div[@class='fixture-card-top']/h5[2]\")\n",
    "    for i in Match_title_tag:\n",
    "        Match_title.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Match_title.append(\"--\")\n",
    "\n",
    "#scraping Series\n",
    "try:\n",
    "    Series_tag= driver_2.find_elements(By.XPATH,\"//div[@class='fixture-card-bottom']\")\n",
    "    for i in Series_tag:\n",
    "        Series.append(i.text.split(\"-\")[0])\n",
    "except NoSuchElementException as e:\n",
    "    Series.append(\"--\")\n",
    "    \n",
    "#scraping Place\n",
    "try:\n",
    "    Place_tag= driver_2.find_elements(By.XPATH,\"//div[@class='fixture-card-bottom']\")\n",
    "    for i in Place_tag:\n",
    "        Place.append(i.text.split(\"-\")[1].replace(\"\\n\",\",\"))\n",
    "except NoSuchElementException as e:\n",
    "    Place.append(\"--\") \n",
    "\n",
    "#scraping Date\n",
    "try:\n",
    "    Date_tag= driver_2.find_elements(By.XPATH,\"//div[@class='match-card-left match-schedule']\")\n",
    "    for i in Date_tag:\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Date.append(\"--\")\n",
    "\n",
    "#scraping Time   \n",
    "try:\n",
    "    Time_tag= driver_2.find_elements(By.XPATH,\"//div[@class='match-card-right match-schedule ']\")\n",
    "    for i in Time_tag:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Time.append(\"--\")\n",
    "\n",
    "#printing length\n",
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))\n",
    "\n",
    "#creating Dataframe\n",
    "international_fixtures=pd.DataFrame({\"Match_title\":Match_title,\"Series\":Series,\"Place\":Place,\"Date\":Date,\"Time\":Time})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4a5813",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f9856ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_3=webdriver.Chrome('chromedriver.exe')\n",
    "driver_3.maximize_window()\n",
    "url=(\"https://www.statisticstimes.com/\")\n",
    "driver_3.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a3e7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "economy = driver_3.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "try:\n",
    "    economy.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver_3.get(economy.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b581df52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_2019</th>\n",
       "      <th>GSDP_2018</th>\n",
       "      <th>Share_2017</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          State  GSDP_2019  GSDP_2018 Share_2017      GDP\n",
       "Rank                                                                     \n",
       "1                   Maharashtra          -  2,632,792     13.94%  399.921\n",
       "2                    Tamil Nadu  1,845,853  1,630,208      8.63%  247.629\n",
       "3                 Uttar Pradesh  1,687,818  1,584,764      8.39%  240.726\n",
       "4                       Gujarat          -  1,502,899      7.96%  228.290\n",
       "5                     Karnataka  1,631,977  1,493,127      7.91%  226.806\n",
       "6                   West Bengal  1,253,832  1,089,898      5.77%  165.556\n",
       "7                     Rajasthan  1,020,989    942,586      4.99%  143.179\n",
       "8                Andhra Pradesh    972,782    862,957      4.57%  131.083\n",
       "9                     Telangana    969,604    861,031      4.56%  130.791\n",
       "10               Madhya Pradesh    906,672    809,592      4.29%  122.977\n",
       "11                       Kerala          -    781,653      4.14%  118.733\n",
       "12                        Delhi    856,112    774,870      4.10%  117.703\n",
       "13                      Haryana    831,610    734,163      3.89%  111.519\n",
       "14                        Bihar    611,804    530,363      2.81%   80.562\n",
       "15                       Punjab    574,760    526,376      2.79%   79.957\n",
       "16                       Odisha    521,275    487,805      2.58%   74.098\n",
       "17                        Assam          -    315,881      1.67%   47.982\n",
       "18                 Chhattisgarh    329,180    304,063      1.61%   46.187\n",
       "19                    Jharkhand    328,598    297,204      1.57%   45.145\n",
       "20                  Uttarakhand          -    245,895      1.30%   37.351\n",
       "21              Jammu & Kashmir          -    155,956      0.83%   23.690\n",
       "22             Himachal Pradesh    165,472    153,845      0.81%   23.369\n",
       "23                          Goa     80,449     73,170      0.39%   11.115\n",
       "24                      Tripura     55,984     49,845      0.26%    7.571\n",
       "25                   Chandigarh          -     42,114      0.22%    6.397\n",
       "26                   Puducherry     38,253     34,433      0.18%    5.230\n",
       "27                    Meghalaya     36,572     33,481      0.18%    5.086\n",
       "28                       Sikkim     32,496     28,723      0.15%    4.363\n",
       "29                      Manipur     31,790     27,870      0.15%    4.233\n",
       "30                     Nagaland          -     27,283      0.14%    4.144\n",
       "31            Arunachal Pradesh          -     24,603      0.13%    3.737\n",
       "32                      Mizoram     26,503     22,287      0.12%    3.385\n",
       "33    Andaman & Nicobar Islands          -          -          -        -"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rank= []\n",
    "State= []\n",
    "GSDP_2019= []\n",
    "GSDP_2018= []\n",
    "Share_2017= []\n",
    "GDP= []\n",
    "\n",
    "#scraping Rank\n",
    "try:\n",
    "    Rank_tag=driver_3.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[1]\")\n",
    "    for i in Rank_tag:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('--')\n",
    "\n",
    "#scraping State\n",
    "try:\n",
    "    State_tag=driver_3.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[2]\")\n",
    "    for i in State_tag:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    State.append('--')\n",
    "\n",
    "#scraping GSDP 2019\n",
    "try:\n",
    "    GSDP_2019_tag=driver_3.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[3]\")\n",
    "    for i in GSDP_2019_tag:\n",
    "        GSDP_2019.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_2019.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    GSDP_2019.append('--')\n",
    "    \n",
    "#scraping GSDP 2018\n",
    "try:\n",
    "    GSDP_2018_tag=driver_3.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[4]\")\n",
    "    for i in GSDP_2018_tag:\n",
    "        GSDP_2018.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_2018.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    GSDP_2018.append('--')\n",
    "    \n",
    "#scraping share 2017\n",
    "try:\n",
    "    Share_2017_tag=driver_3.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[5]\")\n",
    "    for i in Share_2017_tag:\n",
    "        Share_2017.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share_2017.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    Share_2017.append('--')\n",
    "\n",
    "#scraping GDP\n",
    "try:\n",
    "    GDP_tag=driver_3.find_elements(By.XPATH,\"//*[@id='table_id']/tbody/tr/td[6]\")\n",
    "    for i in GDP_tag:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('-')\n",
    "except StaleElementReferenceException:\n",
    "    GDP.append('--')\n",
    "    \n",
    "#printing length\n",
    "print(len(Rank),len(State),len(GSDP_2019),len(GSDP_2018),len(Share_2017),len(GDP))\n",
    "\n",
    "#creating Dataframe\n",
    "State_GDP=pd.DataFrame({\"Rank\":Rank,\"State\":State,\"GSDP_2019\":GSDP_2019,\"GSDP_2018\":GSDP_2018,\"Share_2017\":Share_2017,\"GDP\":GDP}).set_index('Rank')\n",
    "State_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6e929",
   "metadata": {},
   "source": [
    "#  4. Scrape the details of trending repositories on Github.com. \n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f60ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_4=webdriver.Chrome('chromedriver.exe')\n",
    "driver_4.maximize_window()\n",
    "url=(\" https://github.com/\")\n",
    "driver_4.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7959b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on explore sub menu\n",
    "open = driver_4.find_element(By.XPATH,'//button[@class=\"HeaderMenu-link border-0 width-full width-lg-auto px-0 px-lg-2 py-3 py-lg-2 no-wrap d-flex flex-items-center flex-justify-between js-details-target\"]')\n",
    "try:\n",
    "    open.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver_4.get(open.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9f5d792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on Trending under explore sub menu\n",
    "trending = driver_4.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver_4.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver_4.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3039b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Language_used</th>\n",
       "      <th>Contributors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zhayujie / chatgpt-on-wechat</td>\n",
       "      <td>使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...</td>\n",
       "      <td>[Python]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PlexPt / awesome-chatgpt-prompts-zh</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>[6]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rustdesk / rustdesk</td>\n",
       "      <td>Open source virtual / remote desktop infrastru...</td>\n",
       "      <td>[Rust, Dart, C, C++, Kotlin, Python, Other]</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f / awesome-chatgpt-prompts</td>\n",
       "      <td>This repo includes ChatGPT prompt curation to ...</td>\n",
       "      <td>[HTML]</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sashabaranov / go-gpt3</td>\n",
       "      <td>OpenAI GPT-3 and DALL·E API wrapper for Go</td>\n",
       "      <td>[Go, Makefile]</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>openai / gpt-2</td>\n",
       "      <td>Code for the paper \"Language Models are Unsupe...</td>\n",
       "      <td>[Python]</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eliaszon / Programmers-Overseas-Job-Interview-...</td>\n",
       "      <td>🏂🏻 程序员海外工作/英文面试手册</td>\n",
       "      <td>[No, published]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AutumnWhj / ChatGPT-wechat-bot</td>\n",
       "      <td>ChatGPT for wechat https://github.com/AutumnWh...</td>\n",
       "      <td>[TypeScript, JavaScript, Dockerfile, Shell]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cisagov / ESXiArgs-Recover</td>\n",
       "      <td>A tool to recover from ESXiArgs ransomware</td>\n",
       "      <td>[Shell]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fuergaosi233 / wechat-chatgpt</td>\n",
       "      <td>Use ChatGPT On Wechat via wechaty</td>\n",
       "      <td>[TypeScript, Dockerfile, Shell]</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>obi1kenobi / trustfall</td>\n",
       "      <td>If GraphQL were more like SQL: a query languag...</td>\n",
       "      <td>[Rust, TypeScript, Python, Jupyter, 1.3%, 1.2%...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c4s73r / NetworkNightmare</td>\n",
       "      <td>Network Pentesting Mindmap by Caster</td>\n",
       "      <td>[No, published]</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>openai / openai-cookbook</td>\n",
       "      <td>Examples and guides for using the OpenAI API</td>\n",
       "      <td>[Jupyter, 70.6%, 29.4%]</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>YuxinWenRick / hard-prompts-made-easy</td>\n",
       "      <td>eski surum</td>\n",
       "      <td>[Python]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>acikkaynak / deprem-io-frontend</td>\n",
       "      <td>Bu uygulama, ihtiyaç sahibi depremzedelerin ha...</td>\n",
       "      <td>[HTML, JavaScript, CSS]</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>acikkaynak / yardim-agi-flutter</td>\n",
       "      <td>🔮 ChatGPT Desktop Application (Mac, Windows an...</td>\n",
       "      <td>[Dart, JavaScript, HTML, Ruby, Swift, CSS]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lencx / ChatGPT</td>\n",
       "      <td>👁‍🗨 Rare and exotic sats</td>\n",
       "      <td>[Rust, TypeScript, Ruby, Other]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>casey / ord</td>\n",
       "      <td>ChatGPT Java SDK. Lightweight package for inte...</td>\n",
       "      <td>[Rust, HTML, Shell, CSS, JavaScript, Python, Nix]</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PlexPt / chatgpt-java</td>\n",
       "      <td>Cloud Flare scanner</td>\n",
       "      <td>[Java]</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MortezaBashsiz / CFScanner</td>\n",
       "      <td>afetharita.com backend projesi</td>\n",
       "      <td>[Shell]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>acikkaynak / deprem-yardim-backend</td>\n",
       "      <td>RWKV is a RNN with transformer-level LLM perfo...</td>\n",
       "      <td>[Python, Dockerfile, Shell]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BlinkDL / RWKV-LM</td>\n",
       "      <td>🧘‍♀️ Open-source full-stack web development fr...</td>\n",
       "      <td>[Python, Cuda, C++]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Atri-Labs / atrilabs-engine</td>\n",
       "      <td>GPT-3: Language Models are Few-Shot Learners</td>\n",
       "      <td>[TypeScript, JavaScript, Python, CSS, HTML, Do...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai / gpt-3</td>\n",
       "      <td>使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...</td>\n",
       "      <td>[4, Ben, Gretchenmarina, Tom, Brown, Pranav]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>devfullcycle / imersao12</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>[TypeScript, Go, HTML, JavaScript, Shell, Dock...</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Repository_title  \\\n",
       "0                        zhayujie / chatgpt-on-wechat   \n",
       "1                 PlexPt / awesome-chatgpt-prompts-zh   \n",
       "2                                 rustdesk / rustdesk   \n",
       "3                         f / awesome-chatgpt-prompts   \n",
       "4                              sashabaranov / go-gpt3   \n",
       "5                                      openai / gpt-2   \n",
       "6   eliaszon / Programmers-Overseas-Job-Interview-...   \n",
       "7                      AutumnWhj / ChatGPT-wechat-bot   \n",
       "8                          cisagov / ESXiArgs-Recover   \n",
       "9                       fuergaosi233 / wechat-chatgpt   \n",
       "10                             obi1kenobi / trustfall   \n",
       "11                          c4s73r / NetworkNightmare   \n",
       "12                           openai / openai-cookbook   \n",
       "13              YuxinWenRick / hard-prompts-made-easy   \n",
       "14                    acikkaynak / deprem-io-frontend   \n",
       "15                    acikkaynak / yardim-agi-flutter   \n",
       "16                                    lencx / ChatGPT   \n",
       "17                                        casey / ord   \n",
       "18                              PlexPt / chatgpt-java   \n",
       "19                         MortezaBashsiz / CFScanner   \n",
       "20                 acikkaynak / deprem-yardim-backend   \n",
       "21                                  BlinkDL / RWKV-LM   \n",
       "22                        Atri-Labs / atrilabs-engine   \n",
       "23                                     openai / gpt-3   \n",
       "24                           devfullcycle / imersao12   \n",
       "\n",
       "                               Repository_description  \\\n",
       "0   使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...   \n",
       "1                 ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。   \n",
       "2   Open source virtual / remote desktop infrastru...   \n",
       "3   This repo includes ChatGPT prompt curation to ...   \n",
       "4          OpenAI GPT-3 and DALL·E API wrapper for Go   \n",
       "5   Code for the paper \"Language Models are Unsupe...   \n",
       "6                                   🏂🏻 程序员海外工作/英文面试手册   \n",
       "7   ChatGPT for wechat https://github.com/AutumnWh...   \n",
       "8          A tool to recover from ESXiArgs ransomware   \n",
       "9                   Use ChatGPT On Wechat via wechaty   \n",
       "10  If GraphQL were more like SQL: a query languag...   \n",
       "11               Network Pentesting Mindmap by Caster   \n",
       "12       Examples and guides for using the OpenAI API   \n",
       "13                                         eski surum   \n",
       "14  Bu uygulama, ihtiyaç sahibi depremzedelerin ha...   \n",
       "15  🔮 ChatGPT Desktop Application (Mac, Windows an...   \n",
       "16                           👁‍🗨 Rare and exotic sats   \n",
       "17  ChatGPT Java SDK. Lightweight package for inte...   \n",
       "18                                Cloud Flare scanner   \n",
       "19                     afetharita.com backend projesi   \n",
       "20  RWKV is a RNN with transformer-level LLM perfo...   \n",
       "21  🧘‍♀️ Open-source full-stack web development fr...   \n",
       "22       GPT-3: Language Models are Few-Shot Learners   \n",
       "23  使用ChatGPT搭建微信聊天机器人，基于OpenAI API和itchat实现。Wecha...   \n",
       "24                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。   \n",
       "\n",
       "                                        Language_used Contributors_count  \n",
       "0                                            [Python]                  7  \n",
       "1                                                 [6]                 No  \n",
       "2         [Rust, Dart, C, C++, Kotlin, Python, Other]                155  \n",
       "3                                              [HTML]                 59  \n",
       "4                                      [Go, Makefile]                 21  \n",
       "5                                            [Python]                 14  \n",
       "6                                     [No, published]                 No  \n",
       "7         [TypeScript, JavaScript, Dockerfile, Shell]                  4  \n",
       "8                                             [Shell]                  2  \n",
       "9                     [TypeScript, Dockerfile, Shell]                 25  \n",
       "10  [Rust, TypeScript, Python, Jupyter, 1.3%, 1.2%...                  5  \n",
       "11                                    [No, published]                 No  \n",
       "12                            [Jupyter, 70.6%, 29.4%]                 34  \n",
       "13                                           [Python]                  3  \n",
       "14                            [HTML, JavaScript, CSS]                 18  \n",
       "15         [Dart, JavaScript, HTML, Ruby, Swift, CSS]                 23  \n",
       "16                    [Rust, TypeScript, Ruby, Other]                 15  \n",
       "17  [Rust, HTML, Shell, CSS, JavaScript, Python, Nix]                 23  \n",
       "18                                             [Java]                 by  \n",
       "19                                            [Shell]                  4  \n",
       "20                        [Python, Dockerfile, Shell]                 16  \n",
       "21                                [Python, Cuda, C++]                  2  \n",
       "22  [TypeScript, JavaScript, Python, CSS, HTML, Do...                 14  \n",
       "23       [4, Ben, Gretchenmarina, Tom, Brown, Pranav]                  -  \n",
       "24  [TypeScript, Go, HTML, JavaScript, Shell, Dock...                  -  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_title= []\n",
    "Repository_description= []\n",
    "Contributors_count= []\n",
    "Language_used= []\n",
    "urls=[]\n",
    "\n",
    "#Scraping title of repository\n",
    "try:\n",
    "    Repository_title_tag=driver_4.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/h1/a')\n",
    "    for i in Repository_title_tag:\n",
    "        Repository_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_title.append('-')\n",
    "    \n",
    "#Scraping description of Repository\n",
    "try:\n",
    "    description=driver_4.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p')\n",
    "    for i in description:\n",
    "        Repository_description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_description.append('-')\n",
    "\n",
    "for i in [Repository_title_tag,description]:\n",
    "    for j in i:\n",
    "        if i ==Repository_title_tag:\n",
    "            Repository_title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==description:\n",
    "            Repository_description.append(j.text)\n",
    "    \n",
    "for url in urls:\n",
    "    driver_4.get(url)\n",
    "    driver_4.implicitly_wait(3)\n",
    "    div_list=driver_4.find_elements(By.XPATH,'//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    #Scraping count of contributors   \n",
    "    try:\n",
    "        Contributors_count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_count.append('-')\n",
    "    #Scraping used language\n",
    "    try:\n",
    "        Language_used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_used.append('-')\n",
    "        \n",
    "#printing length\n",
    "len(Repository_title),len(Repository_description),len(Language_used),len(Contributors_count)\n",
    "\n",
    "#creating Dataframe\n",
    "github_trending=pd.DataFrame({\"Repository_title\":Repository_title[:25],\"Repository_description\":Repository_description[:25],\"Language_used\":Language_used[:25],\"Contributors_count\":Contributors_count[:25]})\n",
    "github_trending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe00955",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "\n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e097a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_5=webdriver.Chrome('chromedriver.exe')\n",
    "driver_5.maximize_window()\n",
    "url=(\"https://www.billboard.com\")\n",
    "driver_5.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da2ab530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on hot 100\n",
    "charts=driver_5.find_element(By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bf32cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Artist=[]\n",
    "rank=[]\n",
    "\n",
    "#Scraping name\n",
    "Name_tag=driver_5.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "for i in Name_tag:\n",
    "    Name.append(i.text)\n",
    "\n",
    "#Scraping artist\n",
    "Artist_tag=driver_5.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "for i in Artist_tag:\n",
    "    Artist.append(i.text)\n",
    "\n",
    "#Scraping rank\n",
    "rankTag=driver_5.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "for i in rankTag[:3]:\n",
    "    rank.append(i.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "84759eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping name\n",
    "Rank=[]\n",
    "nameTag=driver_5.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in nameTag:\n",
    "    Name.append(i.text )\n",
    "\n",
    "#Scraping artist\n",
    "artistTag=driver_5.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in artistTag:\n",
    "    Artist.append(i.text )\n",
    "\n",
    "#Scraping rank\n",
    "RankTag=driver_5.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "for i in RankTag:\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8cc712f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "941c6a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing Data\n",
    "last_week_rank=Rank[0::3]\n",
    "last_week_rank.insert(0,rank[0])\n",
    "peak_rank=Rank[1::3]\n",
    "peak_rank.insert(0,rank[1])\n",
    "weeks_on_board=Rank[2::3]\n",
    "weeks_on_board.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "67d77eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200, 267, 266, 266)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Name),len(Artist),len(last_week_rank),len(peak_rank),len(weeks_on_board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4a4d2479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 53</td>\n",
       "      <td>Bizarrap &amp; Shakira</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unholy</td>\n",
       "      <td>Sam Smith &amp; Kim Petras</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chorrito Pa Las Animas</td>\n",
       "      <td>Feid</td>\n",
       "      <td>89</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Believer</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>98</td>\n",
       "      <td>52</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Shirt</td>\n",
       "      <td>SZA</td>\n",
       "      <td>76</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dawns</td>\n",
       "      <td>Zach Bryan Featuring Maggie Rogers</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kind Of Love We Make</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>131</td>\n",
       "      <td>38</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name                              Artist  \\\n",
       "0                        Flowers                         Miley Cyrus   \n",
       "1   Bzrp Music Sessions, Vol. 53                  Bizarrap & Shakira   \n",
       "2                      Kill Bill                                 SZA   \n",
       "3                         Unholy              Sam Smith & Kim Petras   \n",
       "4                      Calm Down                 Rema & Selena Gomez   \n",
       "..                           ...                                 ...   \n",
       "95        Chorrito Pa Las Animas                                Feid   \n",
       "96                      Believer                     Imagine Dragons   \n",
       "97                         Shirt                                 SZA   \n",
       "98                         Dawns  Zach Bryan Featuring Maggie Rogers   \n",
       "99      The Kind Of Love We Make                          Luke Combs   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks On Board  \n",
       "0               1         1              3  \n",
       "1               2         2              4  \n",
       "2               3         1              8  \n",
       "3               5         1             19  \n",
       "4               4         3             31  \n",
       "..            ...       ...            ...  \n",
       "95             89        89              4  \n",
       "96             98        52            126  \n",
       "97             76        18             14  \n",
       "98              -        99              1  \n",
       "99            131        38             29  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "songs_top=pd.DataFrame({\"Name\":Name[:100],\"Artist\":Artist[:100],\"Last Week Rank\":last_week_rank[0:100],\"Peak Rank\":peak_rank[0:100],\"Weeks On Board\":weeks_on_board[0:100]})\n",
    "songs_top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64843ba7",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest sellingnovels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "50c2aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_6=webdriver.Chrome('chromedriver.exe')\n",
    "driver_6.maximize_window()\n",
    "url=(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "driver_6.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99c7954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Books=[]\n",
    "Genre=[]\n",
    "\n",
    "#scraping novels\n",
    "try:\n",
    "    Books_tag=driver_6.find_elements(By.XPATH,\"//td[@class='left']\")\n",
    "    for i in Books_tag:\n",
    "        Books.append(i.text)\n",
    "except:\n",
    "    Books.append(\"-\")\n",
    "    \n",
    "#scraping novel's genre\n",
    "try:\n",
    "    Genre_tag=driver_6.find_elements(By.XPATH,\"//td[@class='last left']\")\n",
    "    for i in Genre_tag:\n",
    "        Genre.append(i.text)\n",
    "except:\n",
    "    Genre.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "131bd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing novels data\n",
    "Book_name=Books[1::5]\n",
    "Author_name=Books[2::5]\n",
    "Volumes_sold=Books[3::5]\n",
    "Publisher=Books[4::5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8424298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "#printing length\n",
    "print(len(Book_name), len(Author_name),len(Volumes_sold), len(Publisher), len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "70dcb2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe\n",
    "novels=pd.DataFrame({\"Book Name\":Book_name,\"Author Name\":Author_name,\"Volumes Sold\":Volumes_sold,\"Publisher\":Publisher,\"Genre\":Genre})\n",
    "novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429ac1a",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "610b6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_7=webdriver.Chrome('chromedriver.exe')\n",
    "driver_7.maximize_window()\n",
    "url=(\"http://www.imdb.com/list/ls095964455/\")\n",
    "driver_7.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3eaacd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name= []\n",
    "Year_span= []\n",
    "Genre= []\n",
    "Run_time= []\n",
    "Ratings= []\n",
    "Votes= []\n",
    "\n",
    "#scraping series name\n",
    "try:\n",
    "    Name_tag= driver_7.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in Name_tag:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Name.append(\"--\")\n",
    "\n",
    "#scraping series Year span\n",
    "try:\n",
    "    Year_span_tag= driver_7.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "    for i in Year_span_tag:\n",
    "        Year_span.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Year_span.append(\"--\") \n",
    "    \n",
    "#scraping series Genre\n",
    "try:\n",
    "    Genre_tag= driver_7.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "    for i in Genre_tag:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Genre.append(\"--\")\n",
    "    \n",
    "#scraping series Run Time\n",
    "try:\n",
    "    Run_time_tag= driver_7.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "    for i in Run_time_tag:\n",
    "        Run_time.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Run_time.append(\"--\")\n",
    "    \n",
    "#scraping series Ratings\n",
    "try:\n",
    "    Ratings_tag= driver_7.find_elements(By.XPATH,\"//span[@class='ipl-rating-star__rating']\")\n",
    "    for i in Ratings_tag[::23]:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Ratings.append(\"--\")\n",
    "    \n",
    "#scraping series Votes\n",
    "try:\n",
    "    Votes_tag= driver_7.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "    for i in Votes_tag:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException as e:\n",
    "    Votes.append(\"--\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7607d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "#printing length\n",
    "print(len(Name), len(Year_span), len(Genre), len(Run_time), len(Ratings), len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d43c7362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,122,923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,210,891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,006,887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>297,098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>256,032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>50,730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>62,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>202,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>42,043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>250,717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,122,923  \n",
       "1    51 min     8.7  1,210,891  \n",
       "2    44 min     8.1  1,006,887  \n",
       "3    60 min     7.5    297,098  \n",
       "4    43 min     7.6    256,032  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     50,730  \n",
       "96   50 min     7.8     62,610  \n",
       "97   42 min     8.1    202,902  \n",
       "98   45 min     7.1     42,043  \n",
       "99  572 min     8.6    250,717  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe\n",
    "tv_series= pd.DataFrame({\"Name\":Name[:100],\"Year span\":Year_span[:100],\"Genre\":Genre[:100],\"Run time\":Run_time[:100],\"Ratings\":Ratings[:100],\"Votes\":Votes[:100]})\n",
    "tv_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b62db1",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. \n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c4e847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_8=webdriver.Chrome('chromedriver.exe')\n",
    "driver_8.maximize_window()\n",
    "url=(\"https://archive.ics.uci.edu/\")\n",
    "driver_8.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c19653f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on view all Dataset\n",
    "Dataset= driver_8.find_elements(By.XPATH,\"//span[@class='normal']/b/a\")[0].get_attribute('href')\n",
    "driver_8.get(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d276cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping dataset\n",
    "data=[]\n",
    "try:\n",
    "    data_tag=driver_8.find_elements(By.XPATH,\"//td//p[@class='normal']\")\n",
    "    for i in data_tag[8:4362]:\n",
    "        data.append(i.text )\n",
    "except:\n",
    "    data.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "33fc95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing dataset\n",
    "Dataset_name=data[::7]\n",
    "Data_type=data[1::7]\n",
    "Task=data[2::7]\n",
    "Attribute_type=data[3::7]\n",
    "instances=data[4::7]\n",
    "attribute=data[5::7]\n",
    "Year=data[6::7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "815166c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "#printing length\n",
    "print(len(Dataset_name), len(Data_type), len(Task), len(Attribute_type), len(instances), len(attribute), len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "81c9d84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type Instances Attribute   Year  \n",
       "0    Categorical, Integer, Real      4177         8   1995   \n",
       "1          Categorical, Integer     48842        14   1996   \n",
       "2    Categorical, Integer, Real       798        38          \n",
       "3                   Categorical     37711       294   1998   \n",
       "4    Categorical, Integer, Real       452       279   1998   \n",
       "..                           ...       ...       ...    ...  \n",
       "617               Integer, Real     75840       525   2020   \n",
       "618               Integer, Real       400        50   2020   \n",
       "619                                  1014         7   2020   \n",
       "620                        Real     10129        16   2021   \n",
       "621                        Real      4000         2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating Dataframe\n",
    "Datasets= pd.DataFrame({\"Dataset name\":Dataset_name,\"Data type\":Data_type,\"Task\":Task,\"Attribute type\":Attribute_type,\"Instances\":instances,\"Attribute\":attribute,\"Year\":Year})\n",
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e198c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
