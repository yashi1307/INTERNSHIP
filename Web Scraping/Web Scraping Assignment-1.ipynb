{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f2dd8b",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment-1************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcac14",
   "metadata": {},
   "source": [
    "# 1.  Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29d0b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary libraries:\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffb3ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get required information:\n",
    "\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "Header_Tags = []\n",
    "for i in soup.find_all(class_=\"mw-headline\"):\n",
    "  Header_Tags.append(i.text)\n",
    "\n",
    "Header_Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b434063",
   "metadata": {},
   "source": [
    "# 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5203a232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "IMDB’s Top rated 100 movies\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating of movie</th>\n",
       "      <th>Year of movie released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3/10</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2/10</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9/10</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>9/10</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9/10</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.3/10</td>\n",
       "      <td>(1958)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>8.3/10</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3/10</td>\n",
       "      <td>(1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>8.3/10</td>\n",
       "      <td>(2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3/10</td>\n",
       "      <td>(1931)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Movie Name Rating of movie  \\\n",
       "0                        The Shawshank Redemption          9.3/10   \n",
       "1                                   The Godfather          9.2/10   \n",
       "2                                 The Dark Knight            9/10   \n",
       "3   The Lord of the Rings: The Return of the King            9/10   \n",
       "4                           The Godfather Part II            9/10   \n",
       "..                                            ...             ...   \n",
       "95                                        Vertigo          8.3/10   \n",
       "96                             Lawrence of Arabia          8.3/10   \n",
       "97                                   Citizen Kane          8.3/10   \n",
       "98                                    Toy Story 3          8.3/10   \n",
       "99              M - Eine Stadt sucht einen Mörder          8.3/10   \n",
       "\n",
       "   Year of movie released  \n",
       "0                  (1994)  \n",
       "1                  (1972)  \n",
       "2                  (2008)  \n",
       "3                  (2003)  \n",
       "4                  (1974)  \n",
       "..                    ...  \n",
       "95                 (1958)  \n",
       "96                 (1962)  \n",
       "97                 (1941)  \n",
       "98                 (2010)  \n",
       "99                 (1931)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page1 = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc&count=100&start=1&ref_=adv_nxt')\n",
    "soup1 = BeautifulSoup(page1.content)\n",
    "\n",
    "Name = []\n",
    "\n",
    "for i in soup1.find_all(class_=\"lister-item-header\"):\n",
    "    Name.append(i.text.splitlines()[2])\n",
    "\n",
    "Rating = []\n",
    "for i in soup1.find_all(class_=\"ratings-bar\"):\n",
    "    Rating.append(i.text.split()[13])\n",
    "\n",
    "Release = []\n",
    "for i in soup1.find_all(class_=\"lister-item-year text-muted unbold\"):\n",
    "    Release.append(i.text)\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "print('IMDB’s Top rated 100 movies')\n",
    "print('-'*50)\n",
    "\n",
    "df_1 = pd.DataFrame({'Movie Name':name,'Rating of movie':rating,'Year of movie released':release})\n",
    "\n",
    "df_1.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b7728",
   "metadata": {},
   "source": [
    "# 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "497b8ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "\t\t IMDB’s Top rated 100 Indian movies\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Rating of movie</th>\n",
       "      <th>Year of movie released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Idiots</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black Friday</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guide</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1965)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Masoom</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rangeela</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jaane Tu... Ya Jaane Na</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Socha Na Tha</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Qayamat Se Qayamat Tak</td>\n",
       "      <td>7.4</td>\n",
       "      <td>(1988)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Gunda</td>\n",
       "      <td>7.3</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Movie Name Rating of movie Year of movie released\n",
       "0                   Golmaal             8.5                 (1979)\n",
       "1                  3 Idiots             8.4                 (2009)\n",
       "2              Black Friday             8.4                 (2004)\n",
       "3                     Guide             8.4                 (1965)\n",
       "4                    Masoom             8.4                 (1983)\n",
       "..                      ...             ...                    ...\n",
       "95                 Rangeela             7.4                 (1995)\n",
       "96  Jaane Tu... Ya Jaane Na             7.4                 (2008)\n",
       "97             Socha Na Tha             7.4                 (2005)\n",
       "98   Qayamat Se Qayamat Tak             7.4                 (1988)\n",
       "99                    Gunda             7.3                 (1998)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get requied information:\n",
    "\n",
    "page2 = requests.get('https://www.imdb.com/list/ls009997493/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "\n",
    "Name_1=[]\n",
    "for i in soup2.find_all('h3', class_=\"lister-item-header\"):\n",
    "    cells = i.find_all('a')\n",
    "    Name_1.append(cells[0].text.strip())\n",
    "    \n",
    "Rating_1=[]\n",
    "for i in soup2.find_all('div', class_=\"ipl-rating-star small\"):\n",
    "    Rating_1.append(i.text.replace('\\n',''))\n",
    "\n",
    "Release_1=[]\n",
    "for i in soup2.find_all('span', class_=\"lister-item-year text-muted unbold\"):\n",
    "    Release_1.append(i.text)\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "print('\\t\\t IMDB’s Top rated 100 Indian movies')\n",
    "print('-'*50)\n",
    "\n",
    "df_2 = pd.DataFrame({'Movie Name':Name_1,'Rating of movie':Rating_1,'Year of movie released':Release_1})\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11bac1",
   "metadata": {},
   "source": [
    "# 4. Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) from :\n",
    "\n",
    "https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e06816b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Former Presidents of India\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of President</th>\n",
       "      <th>Term of Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name of President  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13              Dr. Rajendra Prasad (1884-1963)   \n",
       "\n",
       "                                       Term of Office  \n",
       "0                      25 July, 2017 to 25 July, 2022  \n",
       "1                      25 July, 2012 to 25 July, 2017  \n",
       "2                      25 July, 2007 to 25 July, 2012  \n",
       "3                      25 July, 2002 to 25 July, 2007  \n",
       "4                      25 July, 1997 to 25 July, 2002  \n",
       "5                      25 July, 1992 to 25 July, 1997  \n",
       "6                      25 July, 1987 to 25 July, 1992  \n",
       "7                      25 July, 1982 to 25 July, 1987  \n",
       "8                      25 July, 1977 to 25 July, 1982  \n",
       "9                24 August, 1974 to 11 February, 1977  \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "11                        13 May, 1967 to 3 May, 1969  \n",
       "12                       13 May, 1962 to 13 May, 1967  \n",
       "13                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get required information:\n",
    "\n",
    "page3 = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "soup3 = BeautifulSoup(page3.content)\n",
    "\n",
    "President_name=[]\n",
    "for i in soup3.find_all('div', class_=\"presidentListing\"):\n",
    "    cells = i.find_all('h3')\n",
    "    President_name.append(cells[0].text.strip())\n",
    "\n",
    "\n",
    "Term=[]\n",
    "for i in soup3.find_all('div', class_=\"presidentListing\"):\n",
    "    cells = i.find_all('p')\n",
    "    Term.append(cells[0].text.strip().replace('Term of Office:',''))\n",
    "\n",
    "print('-'*50)\n",
    "print('Former Presidents of India')\n",
    "print('-'*50)\n",
    "\n",
    "df_3 = pd.DataFrame({'Name of President':PresidentName,'Term of Office':Term})\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efedee7",
   "metadata": {},
   "source": [
    "# 5. Write a python program to scrape cricket rankings from icc-cricket.com.\n",
    "\n",
    "\n",
    "a)Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5dc1c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Top 10 ODI Teams\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand , NZ</td>\n",
       "      <td>26</td>\n",
       "      <td>3,045</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England , ENG</td>\n",
       "      <td>30</td>\n",
       "      <td>3,400</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Australia , AUS</td>\n",
       "      <td>32</td>\n",
       "      <td>3,572</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India , IND</td>\n",
       "      <td>40</td>\n",
       "      <td>4,377</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pakistan , PAK</td>\n",
       "      <td>25</td>\n",
       "      <td>2,649</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>South Africa , SA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,392</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh , BAN</td>\n",
       "      <td>33</td>\n",
       "      <td>3,129</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri Lanka , SL</td>\n",
       "      <td>33</td>\n",
       "      <td>2,917</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Afghanistan , AFG</td>\n",
       "      <td>20</td>\n",
       "      <td>1,419</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>West Indies , WI</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ranking               Team Matches Points Rating\n",
       "0       1   New Zealand , NZ      26  3,045    117\n",
       "1       2      England , ENG      30  3,400    113\n",
       "2       3    Australia , AUS      32  3,572    112\n",
       "3       4        India , IND      40  4,377    109\n",
       "4       5     Pakistan , PAK      25  2,649    106\n",
       "5       6  South Africa , SA      24  2,392    100\n",
       "6       7   Bangladesh , BAN      33  3,129     95\n",
       "7       8     Sri Lanka , SL      33  2,917     88\n",
       "8       9  Afghanistan , AFG      20  1,419     71\n",
       "9      10   West Indies , WI      41  2,902     71"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get reuired infrormation:\n",
    "\n",
    "page4= requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup4= BeautifulSoup(page4.content)\n",
    "\n",
    "Team=[]\n",
    "Matches=[]\n",
    "Points=[]\n",
    "Rating=[]\n",
    "Ranking=[]\n",
    "for i in soup4.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Ranking.append(cells[0].text.strip())\n",
    "        Team.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Matches.append(cells[2].text.strip())\n",
    "        Points.append(cells[3].text.strip())\n",
    "        Rating.append(cells[4].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print('Top 10 ODI Teams')\n",
    "print('-'*50)\n",
    "\n",
    "df_4= pd.DataFrame({'Ranking':Ranking,'Team':Team,'Matches':Matches,'Points':Points,'Rating':Rating})  \n",
    "df_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf13db",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e91bbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Top 10 ODI Batsmen\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Player Team Rating\n",
       "0             Babar Azam  PAK    891\n",
       "1  Rassie van der Dussen   SA    766\n",
       "2            Imam-ul-Haq  PAK    764\n",
       "3        Quinton de Kock   SA    759\n",
       "4           David Warner  AUS    747\n",
       "5            Virat Kohli  IND    726\n",
       "6            Steve Smith  AUS    719\n",
       "7           Rohit Sharma  IND    715\n",
       "8         Jonny Bairstow  ENG    710\n",
       "9           Fakhar Zaman  PAK    695"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page4_2= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "soup4_2= BeautifulSoup(page4_2.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup4_2.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print(\" Top 10 ODI Batsmen\")\n",
    "print('-'*50)\n",
    "\n",
    "df_4_2= pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})  \n",
    "df_4_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8caa7",
   "metadata": {},
   "source": [
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7291cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "  Top 10 ODI Bowlers\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0        Trent Boult   NZ    744\n",
       "1     Josh Hazlewood  AUS    727\n",
       "2     Mitchell Starc  AUS    665\n",
       "3        Rashid Khan  AFG    659\n",
       "4         Matt Henry   NZ    656\n",
       "5         Adam Zampa  AUS    655\n",
       "6     Shaheen Afridi  PAK    654\n",
       "7    Shakib Al Hasan  BAN    652\n",
       "8  Mustafizur Rahman  BAN    638\n",
       "9   Mujeeb Ur Rahman  AFG    637"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To get required information:\n",
    "\n",
    "page4_3= requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "soup4_3= BeautifulSoup(page4_3.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup4_3.find_all ('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "\n",
    "print('-'*50)\n",
    "print(\"  Top 10 ODI Bowlers\")\n",
    "print('-'*50)\n",
    "\n",
    "df_4_3=pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})\n",
    "df_4_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8589d8c8",
   "metadata": {},
   "source": [
    "# 6. Write a python program to scrape cricket rankings from icc-cricket.com. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2b60b",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc475131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Top 10 ODI Teams in Women\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ranking</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia , AUS</td>\n",
       "      <td>18</td>\n",
       "      <td>3,061</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>England , ENG</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>South Africa , SA</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India , IND</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand , NZ</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies , WI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh , BAN</td>\n",
       "      <td>13</td>\n",
       "      <td>983</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Thailand , THA</td>\n",
       "      <td>8</td>\n",
       "      <td>572</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Pakistan , PAK</td>\n",
       "      <td>24</td>\n",
       "      <td>1,519</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Sri Lanka , SL</td>\n",
       "      <td>8</td>\n",
       "      <td>353</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ranking               Team Matches Points Rating\n",
       "0        1    Australia , AUS      18  3,061    170\n",
       "1        2      England , ENG      28  3,342    119\n",
       "2        3  South Africa , SA      26  3,098    119\n",
       "3        4        India , IND      27  2,820    104\n",
       "4        5   New Zealand , NZ      25  2,553    102\n",
       "5        6   West Indies , WI      27  2,535     94\n",
       "6        7   Bangladesh , BAN      13    983     76\n",
       "7        8     Thailand , THA       8    572     72\n",
       "8        9     Pakistan , PAK      24  1,519     63\n",
       "9       10     Sri Lanka , SL       8    353     44"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5_1 = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup5_1 = BeautifulSoup(page5_1.content)\n",
    "\n",
    "Matches = []\n",
    "Points = []\n",
    "Rating = []\n",
    "Team = []\n",
    "Ranking = []\n",
    "\n",
    "for i in soup5_1.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Ranking.append(cells[0].text.strip())\n",
    "        Team.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Matches.append(cells[2].text.strip())\n",
    "        Points.append(cells[3].text.strip())\n",
    "        Rating.append(cells[4].text.strip())\n",
    "\n",
    "print('-'*50)\n",
    "print(\" Top 10 ODI Teams in Women\")\n",
    "print('-'*50)\n",
    "\n",
    "df_5_1 = pd.DataFrame({' Ranking':Ranking,'Team':Team,'Matches':Matches,'Points':Points,'Rating':Rating})  \n",
    "df_5_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ddfe44",
   "metadata": {},
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a3af273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "  Top 10 ODI Batting Players in Women's\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player Team Rating\n",
       "0         Alyssa Healy  AUS    785\n",
       "1          Beth Mooney  AUS    749\n",
       "2      Laura Wolvaardt   SA    732\n",
       "3       Natalie Sciver  ENG    731\n",
       "4     Harmanpreet Kaur  IND    716\n",
       "5      Smriti Mandhana  IND    714\n",
       "6          Meg Lanning  AUS    710\n",
       "7       Rachael Haynes  AUS    701\n",
       "8  Chamari Athapaththu   SL    655\n",
       "9         Ellyse Perry  AUS    642"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5_2= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "soup5_2= BeautifulSoup(page5_2.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup5_2.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print(\"  Top 10 ODI Batting Players in Women's\")\n",
    "print('-'*50)\n",
    "\n",
    "df_5_2= pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})  \n",
    "df_5_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8c7f01",
   "metadata": {},
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e376d372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Top 10 women’s ODI all-rounder\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player Team Rating\n",
       "0       Ellyse Perry  AUS    374\n",
       "1    Hayley Matthews   WI    373\n",
       "2     Natalie Sciver  ENG    371\n",
       "3     Marizanne Kapp   SA    349\n",
       "4        Amelia Kerr   NZ    336\n",
       "5      Deepti Sharma  IND    322\n",
       "6   Ashleigh Gardner  AUS    270\n",
       "7      Jess Jonassen  AUS    246\n",
       "8     Jhulan Goswami  IND    214\n",
       "9  Sophie Ecclestone  ENG    205"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page5_3= requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "soup5_3= BeautifulSoup(page5_3.content)\n",
    "\n",
    "Player=[]\n",
    "Team=[]\n",
    "Rating=[]\n",
    "\n",
    "for i in soup5_3.find_all('tr')[:11]:\n",
    "    cells = i.find_all('td')\n",
    "    if len(cells) == 5:\n",
    "        Player.append(cells[1].text.strip().replace('\\n',\" , \"))\n",
    "        Team.append(cells[2].text.strip())\n",
    "        Rating.append(cells[3].text.strip())\n",
    "        \n",
    "print('-'*50)\n",
    "print(\"Top 10 women’s ODI all-rounder\")\n",
    "print('-'*50)\n",
    "\n",
    "\n",
    "df_5_3= pd.DataFrame({'Player':Player,'Team':Team,'Rating':Rating})  \n",
    "df_5_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa55470",
   "metadata": {},
   "source": [
    "# 7.  Write a python program to scrape mentioned news details from:\n",
    "\n",
    "https://www.cnbc.com/world/?region=world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303afcf0",
   "metadata": {},
   "source": [
    "**To find:**\n",
    "\n",
    "           i) Headline \n",
    "           ii) Time \n",
    "           iii) News Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02eca197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "News Fetched\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>More classified documents found at Biden’s Del...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/white-house-sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The biggest risks of using Bluetooth trackers ...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/the-biggest-se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veganuary: 3 ways to meet your protein goals o...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/veganuary-3-wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Investing in last year's top 10 stocks is 'a r...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/best-performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 side hustles for introverts: Some can bring ...</td>\n",
       "      <td>19 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/side-hustles-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Here are the odds you'll win the $404 million ...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/powerball-odds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The condo king of Miami is betting big on a ne...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/condo-king-mia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Carmakers upgrade lineups to meet high-end dem...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/carmakers-upgr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What it’s like to deliver for Amazon in new el...</td>\n",
       "      <td>20 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/what-its-like-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The bold bullish case to be made for U.S. stocks</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/the-bold-bulli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Earnings stars: Stocks expected to post the bi...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/earnings-stars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Morgan Stanley says these are the most underva...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/stocks-like-di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stocks on a roll. But overbought market, earni...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/investing-club...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The zero-fare public transit movement is picki...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/zero-fare-publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Building self-discipline by age 27 is crucial,...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/psychiatrist-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Iran executes British-Iranian national despite...</td>\n",
       "      <td>January 14, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/14/iran-executes-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rising commodities prices could be a tailwind ...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/rising-commodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cramer's lightning round: Costamare is not a buy</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cramer’s week ahead: Wait before trading on co...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CDC review finds it’s unlikely Pfizer booster ...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/pfizer-covid-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>House targets China, abortion, IRS funding in ...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/gop-house-targ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pro Picks: Watch all of Friday's big stock cal...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rep. Santos admits he 'embellished' his resume...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/george-santos-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6 question on meditation, answered by an expert</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/6-meditation-q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Trump denies rape in testimony, falsely says a...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/trump-depositi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>House Republicans move to regulate crypto indu...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/house-republic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JPMorgan says college-planning firm it bought ...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/jpmorgan-says-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bill Gates: We will overshoot 1.5 degrees Cels...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/bill-gates-we-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Take profits on Starbucks after its huge run, ...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/take-profits-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Hasbro delays Dungeons &amp; Dragons licensing dea...</td>\n",
       "      <td>January 13, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/01/13/hasbro-delays-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline              Time  \\\n",
       "0   More classified documents found at Biden’s Del...      17 Hours Ago   \n",
       "1   The biggest risks of using Bluetooth trackers ...      17 Hours Ago   \n",
       "2   Veganuary: 3 ways to meet your protein goals o...      19 Hours Ago   \n",
       "3   Investing in last year's top 10 stocks is 'a r...      19 Hours Ago   \n",
       "4   4 side hustles for introverts: Some can bring ...      19 Hours Ago   \n",
       "5   Here are the odds you'll win the $404 million ...      20 Hours Ago   \n",
       "6   The condo king of Miami is betting big on a ne...      20 Hours Ago   \n",
       "7   Carmakers upgrade lineups to meet high-end dem...      20 Hours Ago   \n",
       "8   What it’s like to deliver for Amazon in new el...      20 Hours Ago   \n",
       "9    The bold bullish case to be made for U.S. stocks      21 Hours Ago   \n",
       "10  Earnings stars: Stocks expected to post the bi...      21 Hours Ago   \n",
       "11  Morgan Stanley says these are the most underva...      21 Hours Ago   \n",
       "12  Stocks on a roll. But overbought market, earni...      21 Hours Ago   \n",
       "13  The zero-fare public transit movement is picki...      21 Hours Ago   \n",
       "14  Building self-discipline by age 27 is crucial,...      21 Hours Ago   \n",
       "15  Iran executes British-Iranian national despite...  January 14, 2023   \n",
       "16  Rising commodities prices could be a tailwind ...  January 13, 2023   \n",
       "17   Cramer's lightning round: Costamare is not a buy  January 13, 2023   \n",
       "18  Cramer’s week ahead: Wait before trading on co...  January 13, 2023   \n",
       "19  CDC review finds it’s unlikely Pfizer booster ...  January 13, 2023   \n",
       "20  House targets China, abortion, IRS funding in ...  January 13, 2023   \n",
       "21  Pro Picks: Watch all of Friday's big stock cal...  January 13, 2023   \n",
       "22  Rep. Santos admits he 'embellished' his resume...  January 13, 2023   \n",
       "23   6 question on meditation, answered by an expert   January 13, 2023   \n",
       "24  Trump denies rape in testimony, falsely says a...  January 13, 2023   \n",
       "25  House Republicans move to regulate crypto indu...  January 13, 2023   \n",
       "26  JPMorgan says college-planning firm it bought ...  January 13, 2023   \n",
       "27  Bill Gates: We will overshoot 1.5 degrees Cels...  January 13, 2023   \n",
       "28  Take profits on Starbucks after its huge run, ...  January 13, 2023   \n",
       "29  Hasbro delays Dungeons & Dragons licensing dea...  January 13, 2023   \n",
       "\n",
       "                                            News link  \n",
       "0   https://www.cnbc.com/2023/01/14/white-house-sa...  \n",
       "1   https://www.cnbc.com/2023/01/14/the-biggest-se...  \n",
       "2   https://www.cnbc.com/2023/01/14/veganuary-3-wa...  \n",
       "3   https://www.cnbc.com/2023/01/14/best-performin...  \n",
       "4   https://www.cnbc.com/2023/01/14/side-hustles-f...  \n",
       "5   https://www.cnbc.com/2023/01/14/powerball-odds...  \n",
       "6   https://www.cnbc.com/2023/01/14/condo-king-mia...  \n",
       "7   https://www.cnbc.com/2023/01/14/carmakers-upgr...  \n",
       "8   https://www.cnbc.com/2023/01/14/what-its-like-...  \n",
       "9   https://www.cnbc.com/2023/01/14/the-bold-bulli...  \n",
       "10  https://www.cnbc.com/2023/01/14/earnings-stars...  \n",
       "11  https://www.cnbc.com/2023/01/14/stocks-like-di...  \n",
       "12  https://www.cnbc.com/2023/01/14/investing-club...  \n",
       "13  https://www.cnbc.com/2023/01/14/zero-fare-publ...  \n",
       "14  https://www.cnbc.com/2023/01/14/psychiatrist-f...  \n",
       "15  https://www.cnbc.com/2023/01/14/iran-executes-...  \n",
       "16  https://www.cnbc.com/2023/01/13/rising-commodi...  \n",
       "17  https://www.cnbc.com/2023/01/13/cramers-lightn...  \n",
       "18  https://www.cnbc.com/2023/01/13/cramers-week-a...  \n",
       "19  https://www.cnbc.com/2023/01/13/pfizer-covid-b...  \n",
       "20  https://www.cnbc.com/2023/01/13/gop-house-targ...  \n",
       "21  https://www.cnbc.com/2023/01/13/pro-picks-watc...  \n",
       "22  https://www.cnbc.com/2023/01/13/george-santos-...  \n",
       "23  https://www.cnbc.com/2023/01/13/6-meditation-q...  \n",
       "24  https://www.cnbc.com/2023/01/13/trump-depositi...  \n",
       "25  https://www.cnbc.com/2023/01/13/house-republic...  \n",
       "26  https://www.cnbc.com/2023/01/13/jpmorgan-says-...  \n",
       "27  https://www.cnbc.com/2023/01/13/bill-gates-we-...  \n",
       "28  https://www.cnbc.com/2023/01/13/take-profits-o...  \n",
       "29  https://www.cnbc.com/2023/01/13/hasbro-delays-...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page6= requests.get('https://www.cnbc.com/world/?region=world')\n",
    "soup6= BeautifulSoup(page6.content)\n",
    "\n",
    "Headline = []\n",
    "for i in soup6.find_all('a', class_=\"LatestNews-headline\"):\n",
    "    Headline.append(i.get('title'))\n",
    "\n",
    "\n",
    "Time = []\n",
    "for i in soup6.find_all('span', class_=\"LatestNews-wrapper\"):\n",
    "    Time.append(i.text)\n",
    "\n",
    "NewsLink = []\n",
    "for i in soup6.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    NewsLink.append(i.get('href'))\n",
    "    \n",
    "print('-'*50)\n",
    "print(\"News Fetched\")\n",
    "print('-'*50)\n",
    "\n",
    "\n",
    "df_6= pd.DataFrame({'Headline':Headline,'Time':Time,'News link':NewsLink})  \n",
    "df_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e34a86c",
   "metadata": {},
   "source": [
    "# 8. Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "\n",
    "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a4fa89",
   "metadata": {},
   "source": [
    "**To find:**\n",
    "\n",
    "         i) Paper Title \n",
    "        ii) Authors \n",
    "        iii)Published Date\n",
    "        iv) Paper URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e549981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Details of Most Downloaded Articles\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_7= requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "soup_7= BeautifulSoup(page_7.content)\n",
    "\n",
    "Paper_Title=[]\n",
    "for i in soup_7.find_all('h2', class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    Paper_Title.append(i.text)\n",
    "\n",
    "Authors=[]\n",
    "for i in soup_7.find_all('span', class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    Authors.append(i.text)  \n",
    "\n",
    "Published_Date=[]\n",
    "for i in soup_7.find_all('span', class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    Published_Date.append(i.text)  \n",
    "\n",
    "Paper_URL=[]\n",
    "for i in soup_7.find_all('a', class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    Paper_URL.append(i.get('href'))\n",
    "\n",
    "print('-'*50)\n",
    "print(' Details of Most Downloaded Articles')\n",
    "print('-'*50)\n",
    "\n",
    "df_7=pd.DataFrame({'Paper Title': Paper_Title,'Authors': Authors,'Published Date': Published_Date, 'Paper URL':Paper_URL})\n",
    "df_7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd18f57",
   "metadata": {},
   "source": [
    "# 9. Write a python program to scrape mentioned details from :\n",
    "\n",
    "dineout.co.in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bff85c",
   "metadata": {},
   "source": [
    "**To find**\n",
    "\n",
    "    i) Restaurant name\n",
    "    ii) Cuisine\n",
    "    iii) Location\n",
    "    iv) Ratings\n",
    "    v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "814e9847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      " Details\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian,</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Restaurant_Name               Cuisine  \\\n",
       "0                   Castle Barbeque        Chinese, North   \n",
       "1                   Jungle Jamboree         North Indian,   \n",
       "2                        Cafe Knosh  Italian, Continental   \n",
       "3                   Castle Barbeque        Chinese, North   \n",
       "4              The Barbeque Company         North Indian,   \n",
       "5                       India Grill         North Indian,   \n",
       "6                    Delhi Barbeque          North Indian   \n",
       "7  The Monarch - Bar Be Que Village          North Indian   \n",
       "8                 Indian Grill Room         North Indian,   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi     4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida       4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.6   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image_URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_8= requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup_8= BeautifulSoup(page_8.content)\n",
    "\n",
    "restaurant_name= []\n",
    "for i in soup_8.find_all('a', class_=\"restnt-name ellipsis\"):\n",
    "    restaurant_name.append(i.text)\n",
    "\n",
    "Cuisine=[]\n",
    "for i in soup_8.find_all('div', class_=\"detail-info\"):\n",
    "    Cuisine.append((i.text.split()[6])+(' ')+(i.text.split()[7]))\n",
    "\n",
    "\n",
    "location=[]\n",
    "for i in soup_8.find_all('div', class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "\n",
    "Ratings= []\n",
    "for i in soup_8.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    Ratings.append(i.text)\n",
    "\n",
    "Image_URL= []\n",
    "for i in soup_8.find_all('img', class_=\"no-img\"):\n",
    "    Image_URL.append(i['data-src'])\n",
    "\n",
    "\n",
    "print('-'*50)\n",
    "print(' Details')\n",
    "print('-'*50)\n",
    "\n",
    "df_8=pd.DataFrame({'Restaurant_Name':restaurant_name,'Cuisine':Cuisine,'Location':location,'Ratings':Ratings,'Image_URL':Image_URL})\n",
    "df_8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116f6bb",
   "metadata": {},
   "source": [
    "**Note : Question-10 is skipped(As informed) , because of error.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
